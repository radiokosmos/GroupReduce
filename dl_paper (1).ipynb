{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NFdz5c7CxNyq"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "import torch\n",
    "import torch.nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from lm import repackage_hidden, LM_LSTM\n",
    "import numpy as np\n",
    "import reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oQ2Z7nR3mBVY"
   },
   "source": [
    "Ниже - обучение базовой модели из статьи: bigLSTM(small PTB)\n",
    "Обученная модель сохранена в файле lm_model.pt  \n",
    "Поэтому это можно скипнуть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4prWa3UzyNGg"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "data = 'data'\n",
    "hidden_size = 200\n",
    "num_steps = 35\n",
    "num_layers = 2\n",
    "batch_size = 20\n",
    "num_epochs = 13 \n",
    "dp_keep_prob = 0.35\n",
    "inital_lr = 20.0\n",
    "save = 'lm_model.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oOZhDYxL6mAT"
   },
   "outputs": [],
   "source": [
    "def repackage_hidden(h):\n",
    "  \"\"\"Wraps hidden states in new Variables, to detach them from their history.\"\"\"\n",
    "  \n",
    "\n",
    "  if type(h) == torch.Tensor:\n",
    "    return Variable(h.data)\n",
    "  else:\n",
    "    d = tuple(repackage_hidden(v) for v in h)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xK-sZhMs2Tq8"
   },
   "outputs": [],
   "source": [
    "def run_epoch(model, data, is_train=False, lr=1.0):\n",
    "    \"\"\"Runs the model on the given data.\"\"\"\n",
    "    if is_train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    epoch_size = ((len(data) // model.batch_size) - 1) // model.num_steps\n",
    "    start_time = time.time()\n",
    "    hidden = model.init_hidden()\n",
    "    hidden[0].requires_grad=True\n",
    "    hidden[1].requires_grad=True\n",
    "    costs = 0.0\n",
    "    iters = 0\n",
    "    for step, (x, y) in enumerate(reader.ptb_iterator(data, model.batch_size, model.num_steps)):\n",
    "        inputs =torch.from_numpy(x.astype(np.int64)).transpose(0, 1).contiguous().cuda()\n",
    "        model.zero_grad()\n",
    "        hidden = repackage_hidden(hidden)\n",
    "        outputs, hidden = model(inputs, hidden)\n",
    "        targets = torch.from_numpy(y.astype(np.int64)).transpose(0, 1).contiguous().cuda()\n",
    "        tt = torch.squeeze(targets.view(-1, model.batch_size * model.num_steps))\n",
    "\n",
    "        loss = criterion(outputs.view(-1, model.vocab_size), tt)\n",
    "        #print( loss.data.item() , model.num_steps)\n",
    "        costs += loss.data.item() * model.num_steps\n",
    "        iters += model.num_steps\n",
    "\n",
    "        if is_train:\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm(model.parameters(), 0.25)\n",
    "            for p in model.parameters():\n",
    "                p.data.add_(-lr, p.grad.data)\n",
    "            if step % (epoch_size // 10) == 10:\n",
    "                print(\"{} perplexity: {:8.2f} speed: {} wps\".format(step * 1.0 / epoch_size, np.exp(costs / iters),\n",
    "                                                       iters * model.batch_size / (time.time() - start_time)))\n",
    "    return np.exp(costs / iters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cPpy_FSz0n3V"
   },
   "outputs": [],
   "source": [
    "#for google collab\n",
    "!mkdir /content/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2758
    },
    "colab_type": "code",
    "id": "tINPnduTz_tI",
    "outputId": "f7abc1b5-cab0-45ea-9a4b-f8f4d1c49475"
   },
   "outputs": [],
   "source": [
    "\n",
    "raw_data = reader.ptb_raw_data(data_path=data)\n",
    "train_data, valid_data, test_data, word_to_id, id_2_word = raw_data\n",
    "vocab_size = len(word_to_id)\n",
    "print('Vocabluary size: {}'.format(vocab_size))\n",
    "model = LM_LSTM(embedding_dim=hidden_size, num_steps=num_steps, batch_size=batch_size,\n",
    "                vocab_size=vocab_size, num_layers=num_layers, dp_keep_prob=dp_keep_prob)\n",
    "model.cuda()\n",
    "lr = inital_lr\n",
    "# decay factor for learning rate\n",
    "lr_decay_base = 1 / 1.15\n",
    "# we will not touch lr for the first m_flat_lr epochs\n",
    "m_flat_lr = 14.0\n",
    "\n",
    "print(\"########## Training ##########################\")\n",
    "for epoch in range(num_epochs):\n",
    "    lr_decay = lr_decay_base ** max(epoch - m_flat_lr, 0)\n",
    "    lr = lr * lr_decay # decay lr if it is time\n",
    "    train_p = run_epoch(model, train_data, True, lr)\n",
    "    print('Train perplexity at epoch {}: {:8.2f}'.format(epoch, train_p))\n",
    "    print('Validation perplexity at epoch {}: {:8.2f}'.format(epoch, run_epoch(model, valid_data)))\n",
    "print(\"########## Testing ##########################\")\n",
    "model.batch_size = 1 # to make sure we process all the data\n",
    "print('Test Perplexity: {:8.2f}'.format(run_epoch(model, test_data)))\n",
    "with open(save, 'wb') as f:\n",
    "    torch.save(model, f)\n",
    "print(\"########## Done! ##########################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WG-RPKlZmtnM"
   },
   "source": [
    "Загрузка обученной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "thTFxgR2T8jD",
    "outputId": "9fc01ef6-8a3b-4db9-9d36-9c02ec7ac3d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabluary size: 10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LM_LSTM(\n",
       "  (dropout): Dropout(p=0.65)\n",
       "  (word_embeddings): Embedding(10000, 1500)\n",
       "  (lstm): LSTM(1500, 1500, num_layers=2, dropout=0.65)\n",
       "  (sm_fc): Linear(in_features=1500, out_features=10000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = reader.ptb_raw_data(data_path=data)\n",
    "train_data, valid_data, test_data, word_to_id, id_2_word = raw_data\n",
    "vocab_size = len(word_to_id)\n",
    "print('Vocabluary size: {}'.format(vocab_size))\n",
    "model =  torch.load('./lm_model.pt')\n",
    "model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zOV2GEOjhKn_"
   },
   "outputs": [],
   "source": [
    "freq = {key:0 for key in id_2_word.keys()}\n",
    "for j in train_data:\n",
    "    freq[j] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "boaXGwroA_9l"
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "freq_sqr = np.array([sqrt(q) for key, q in freq.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qx8P53jR9yVl"
   },
   "outputs": [],
   "source": [
    "def weighted_svd(A, freq_sqr): \n",
    "    Q = torch.diag(torch.from_numpy(freq_sqr).cuda().type(torch.cuda.FloatTensor))\n",
    "    QA = torch.matmul(Q, A)\n",
    "    U_, S_, V_ = torch.svd(QA)\n",
    "    #print(Q.shape, V_.shape, S_.shape)\n",
    "    #print(torch.matmul(torch.inverse(Q),U_).shape)\n",
    "    U = torch.matmul(torch.inverse(Q),U_) * S_\n",
    "    return U, V_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "cOQl3NMhJOIk",
    "outputId": "5cd86d15-0419-402a-8a89-e7bcda95d555"
   },
   "outputs": [],
   "source": [
    "w=model.word_embeddings.weight\n",
    "U, V = weighted_svd(w, freq_sqr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "cmJyuzKrfUrh",
    "outputId": "5d4d7455-5426-446c-ee69-597a6462f320"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 1500])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_weights = torch.matmul(U, V.t())\n",
    "new_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_sqr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dkkv_aZPpDW-"
   },
   "outputs": [],
   "source": [
    "def group_reduce(A, c, r, t_max, m_min):\n",
    "    #init clusters\n",
    "    m = 5\n",
    "    cluster_len = A.shape[0] / c\n",
    "    clusters = torch.split(A, int(cluster_len))\n",
    "    freq_cls = np.array_split(freq_sqr, c)\n",
    "    ranks = {}\n",
    "    V = {}\n",
    "    U = {}\n",
    "    for p in range(c): \n",
    "        U[p], V[p]  = weighted_svd(clusters[p],freq_cls[p])\n",
    "        ranks[p] = torch.matrix_rank(torch.matmul(U[p], V[p].t()))\n",
    "    for t in range(t_max):\n",
    "        M = {}\n",
    "        for i in range(A.shape[0]):\n",
    "            errors = [torch.norm(A[i] - torch.matmul(torch.matmul(V[p], V[p].t()), A[i])) for p in range(c)]\n",
    "            e_i = min(errors)\n",
    "            g_i = np.argmin(errors)\n",
    "            if g_i != i // cluster_len:\n",
    "                M[i] = (e_i, g_i)\n",
    "        print(M)\n",
    "        t = 0\n",
    "        is_changed = [False]*c\n",
    "        for key, value in sorted(M.items(), key=lambda kv: kv[1]):\n",
    "            freq_cls[value[1]].append(freq_cls[key // cluster_len][key % cluster_len])\n",
    "            freq_cls[key // cluster_len].delete(freq_cls[key // cluster_len][key % cluster_len])\n",
    "            clusters[value[1]] = torch.cat(clusters[value[1]], clusters[key // cluster_len][key % cluster_len])\n",
    "            clusters[key // cluster_len] = torch.cat(clusters[key // cluster_len][ :key % cluster_len], \n",
    "                                                     clusters[key // cluster_len][key % cluster_len + 1: ]) \n",
    "            is_chaged[value[1]] = True\n",
    "            is_chaged[key // cluster_len] = True\n",
    "            \n",
    "            t += 1\n",
    "            if m == t:\n",
    "                break;\n",
    "        if m < m_min:\n",
    "            return [torch.matmul(U[p], V[p].t()) for p in range(c)]\n",
    "        for p in range(c):\n",
    "            if is_changed[p]:\n",
    "                U[p], V[p]  = weighted_svd(clusters[p],freq_cls[p])\n",
    "                ranks[p] = torch.matrix_rank(torch.matmul(U[p], V[p].t()))\n",
    "    return [torch.matmul(U[p], V[p].t()) for p in range(c)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "group_reduce(w, c = 10, r = 10, t_max = 100, m_min = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = {1: (2, 1), 3: (4, 0), 4: (3, 1), 2: (1, 5), 0: (0, 6)}\n",
    "sorted_by_value = sorted(x.items(), key=lambda kv: kv[1])\n",
    "sorted_by_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [1, 2, 3, 4, 5, 6]\n",
    "A[0:2-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[[1, 2],[3, 4]],[[5, 6],[7, 8]],[[9, 0],[11,12]]])\n",
    "A_tensor = torch.from_numpy(A)\n",
    "A_tensor"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "dl_paper.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
