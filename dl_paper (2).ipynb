{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NFdz5c7CxNyq"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "import torch\n",
    "import torch.nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from lm import repackage_hidden, LM_LSTM\n",
    "import numpy as np\n",
    "import reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oQ2Z7nR3mBVY"
   },
   "source": [
    "Ниже - обучение базовой модели из статьи: bigLSTM(small PTB)\n",
    "Обученная модель сохранена в файле lm_model.pt  \n",
    "Поэтому это можно скипнуть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4prWa3UzyNGg"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "data = 'data'\n",
    "hidden_size = 200\n",
    "num_steps = 35\n",
    "num_layers = 2\n",
    "batch_size = 20\n",
    "num_epochs = 13 \n",
    "dp_keep_prob = 0.35\n",
    "inital_lr = 20.0\n",
    "save = 'lm_model.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oOZhDYxL6mAT"
   },
   "outputs": [],
   "source": [
    "def repackage_hidden(h):\n",
    "  \"\"\"Wraps hidden states in new Variables, to detach them from their history.\"\"\"\n",
    "  \n",
    "\n",
    "  if type(h) == torch.Tensor:\n",
    "    return Variable(h.data)\n",
    "  else:\n",
    "    d = tuple(repackage_hidden(v) for v in h)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xK-sZhMs2Tq8"
   },
   "outputs": [],
   "source": [
    "def run_epoch(model, data, is_train=False, lr=1.0):\n",
    "    \"\"\"Runs the model on the given data.\"\"\"\n",
    "    if is_train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    epoch_size = ((len(data) // model.batch_size) - 1) // model.num_steps\n",
    "    start_time = time.time()\n",
    "    hidden = model.init_hidden()\n",
    "    hidden[0].requires_grad=True\n",
    "    hidden[1].requires_grad=True\n",
    "    costs = 0.0\n",
    "    iters = 0\n",
    "    for step, (x, y) in enumerate(reader.ptb_iterator(data, model.batch_size, model.num_steps)):\n",
    "        inputs =torch.from_numpy(x.astype(np.int64)).transpose(0, 1).contiguous().cuda()\n",
    "        model.zero_grad()\n",
    "        hidden = repackage_hidden(hidden)\n",
    "        outputs, hidden = model(inputs, hidden)\n",
    "        targets = torch.from_numpy(y.astype(np.int64)).transpose(0, 1).contiguous().cuda()\n",
    "        tt = torch.squeeze(targets.view(-1, model.batch_size * model.num_steps))\n",
    "\n",
    "        loss = criterion(outputs.view(-1, model.vocab_size), tt)\n",
    "        #print( loss.data.item() , model.num_steps)\n",
    "        costs += loss.data.item() * model.num_steps\n",
    "        iters += model.num_steps\n",
    "\n",
    "        if is_train:\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm(model.parameters(), 0.25)\n",
    "            for p in model.parameters():\n",
    "                p.data.add_(-lr, p.grad.data)\n",
    "            if step % (epoch_size // 10) == 10:\n",
    "                print(\"{} perplexity: {:8.2f} speed: {} wps\".format(step * 1.0 / epoch_size, np.exp(costs / iters),\n",
    "                                                       iters * model.batch_size / (time.time() - start_time)))\n",
    "    return np.exp(costs / iters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cPpy_FSz0n3V"
   },
   "outputs": [],
   "source": [
    "#for google collab\n",
    "!mkdir /content/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2758
    },
    "colab_type": "code",
    "id": "tINPnduTz_tI",
    "outputId": "f7abc1b5-cab0-45ea-9a4b-f8f4d1c49475"
   },
   "outputs": [],
   "source": [
    "\n",
    "raw_data = reader.ptb_raw_data(data_path=data)\n",
    "train_data, valid_data, test_data, word_to_id, id_2_word = raw_data\n",
    "vocab_size = len(word_to_id)\n",
    "print('Vocabluary size: {}'.format(vocab_size))\n",
    "model = LM_LSTM(embedding_dim=hidden_size, num_steps=num_steps, batch_size=batch_size,\n",
    "                vocab_size=vocab_size, num_layers=num_layers, dp_keep_prob=dp_keep_prob)\n",
    "model.cuda()\n",
    "lr = inital_lr\n",
    "# decay factor for learning rate\n",
    "lr_decay_base = 1 / 1.15\n",
    "# we will not touch lr for the first m_flat_lr epochs\n",
    "m_flat_lr = 14.0\n",
    "\n",
    "print(\"########## Training ##########################\")\n",
    "for epoch in range(num_epochs):\n",
    "    lr_decay = lr_decay_base ** max(epoch - m_flat_lr, 0)\n",
    "    lr = lr * lr_decay # decay lr if it is time\n",
    "    train_p = run_epoch(model, train_data, True, lr)\n",
    "    print('Train perplexity at epoch {}: {:8.2f}'.format(epoch, train_p))\n",
    "    print('Validation perplexity at epoch {}: {:8.2f}'.format(epoch, run_epoch(model, valid_data)))\n",
    "print(\"########## Testing ##########################\")\n",
    "model.batch_size = 1 # to make sure we process all the data\n",
    "print('Test Perplexity: {:8.2f}'.format(run_epoch(model, test_data)))\n",
    "with open(save, 'wb') as f:\n",
    "    torch.save(model, f)\n",
    "print(\"########## Done! ##########################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WG-RPKlZmtnM"
   },
   "source": [
    "Загрузка обученной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "thTFxgR2T8jD",
    "outputId": "9fc01ef6-8a3b-4db9-9d36-9c02ec7ac3d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabluary size: 10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LM_LSTM(\n",
       "  (dropout): Dropout(p=0.65)\n",
       "  (word_embeddings): Embedding(10000, 1500)\n",
       "  (lstm): LSTM(1500, 1500, num_layers=2, dropout=0.65)\n",
       "  (sm_fc): Linear(in_features=1500, out_features=10000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = reader.ptb_raw_data(data_path=data)\n",
    "train_data, valid_data, test_data, word_to_id, id_2_word = raw_data\n",
    "vocab_size = len(word_to_id)\n",
    "print('Vocabluary size: {}'.format(vocab_size))\n",
    "model =  torch.load('./lm_model.pt')\n",
    "model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zOV2GEOjhKn_"
   },
   "outputs": [],
   "source": [
    "freq = {key:0 for key in id_2_word.keys()}\n",
    "for j in train_data:\n",
    "    freq[j] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "boaXGwroA_9l"
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "freq_sqr = np.array([sqrt(q) for key, q in freq.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qx8P53jR9yVl"
   },
   "outputs": [],
   "source": [
    "def weighted_svd(A, freq_sqr): \n",
    "    Q = torch.diag(torch.from_numpy(freq_sqr).cuda().type(torch.cuda.FloatTensor))\n",
    "    QA = torch.matmul(Q, A)\n",
    "    U_, S_, V_ = torch.svd(QA)\n",
    "    #print(Q.shape, V_.shape, S_.shape)\n",
    "    #print(torch.matmul(torch.inverse(Q),U_).shape)\n",
    "    U = torch.matmul(torch.inverse(Q),U_) * S_\n",
    "    return U, V_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "cOQl3NMhJOIk",
    "outputId": "5cd86d15-0419-402a-8a89-e7bcda95d555"
   },
   "outputs": [],
   "source": [
    "w=model.word_embeddings.weight\n",
    "U, V = weighted_svd(w, freq_sqr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "cmJyuzKrfUrh",
    "outputId": "5d4d7455-5426-446c-ee69-597a6462f320"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 1500])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_weights = torch.matmul(U, V.t())\n",
    "new_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_sqr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dkkv_aZPpDW-"
   },
   "outputs": [],
   "source": [
    "def group_reduce(A, c, r, t_max, m_min):\n",
    "    #init clusters\n",
    "    cluster_len = A.shape[0] / c\n",
    "    clusters = torch.split(A, int(cluster_len))\n",
    "    freq_cls = np.array_split(freq_sqr, c)\n",
    "    ranks = {}\n",
    "    V = {}\n",
    "    U = {}\n",
    "    for p in range(c): \n",
    "        U[p], V[p]  = weighted_svd(clusters[p],freq_cls[p])\n",
    "        ranks[p] = torch.matrix_rank(torch.matmul(U[p], V[p].t()))\n",
    "    for t in range(t_max):\n",
    "        M = {}\n",
    "        for i in range(A.shape[0]):\n",
    "            errors = [torch.norm(A[i] - torch.matmul(torch.matmul(V[p], V[p].t()), A[i])) for p in range(c)]\n",
    "            e_i = min(errors)\n",
    "            g_i = np.argmin(errors)\n",
    "            if g_i != i // cluster_len:\n",
    "                M[i] = (e_i, g_i)\n",
    "        print(M)\n",
    "        m = 0.1*len(M)\n",
    "        t = 0\n",
    "        is_changed = [False]*c\n",
    "        for key, value in sorted(M.items(), key=lambda kv: kv[1]):\n",
    "            freq_cls[value[1]].append(freq_cls[key // cluster_len][key % cluster_len])\n",
    "            freq_cls[key // cluster_len].delete(freq_cls[key // cluster_len][key % cluster_len])\n",
    "            clusters[value[1]] = torch.cat(clusters[value[1]], clusters[key // cluster_len][key % cluster_len])\n",
    "            clusters[key // cluster_len] = torch.cat(clusters[key // cluster_len][ :key % cluster_len], \n",
    "                                                     clusters[key // cluster_len][key % cluster_len + 1: ]) \n",
    "            is_chaged[value[1]] = True\n",
    "            is_chaged[key // cluster_len] = True\n",
    "            \n",
    "            t += 1\n",
    "            if m == t:\n",
    "                break;\n",
    "        if m < m_min:\n",
    "            return [torch.matmul(U[p], V[p].t()) for p in range(c)]\n",
    "        for p in range(c):\n",
    "            if is_changed[p]:\n",
    "                U[p], V[p]  = weighted_svd(clusters[p],freq_cls[p])\n",
    "                ranks[p] = torch.matrix_rank(torch.matmul(U[p], V[p].t()))\n",
    "    return [torch.matmul(U[p], V[p].t()) for p in range(c)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "{}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.1311,  0.1610, -0.0722,  ...,  0.2115,  0.1102, -0.1117],\n",
       "         [ 0.0727,  0.1335, -0.1277,  ...,  0.3543, -0.0537, -0.0631],\n",
       "         [ 0.1373,  0.3537, -0.2748,  ..., -0.0159, -0.2245, -0.1115],\n",
       "         ...,\n",
       "         [ 0.1178, -0.0063,  0.0412,  ...,  0.1042, -0.0494, -0.0364],\n",
       "         [ 0.0614, -0.1251, -0.0319,  ...,  0.1271,  0.1594, -0.1130],\n",
       "         [ 0.1573,  0.1949,  0.0006,  ...,  0.1193, -0.0180, -0.0163]],\n",
       "        device='cuda:0', grad_fn=<MmBackward>),\n",
       " tensor([[ 0.1173,  0.0042,  0.0267,  ..., -0.0471, -0.0061,  0.0128],\n",
       "         [-0.1184,  0.0134,  0.0045,  ..., -0.0175, -0.0679, -0.1969],\n",
       "         [ 0.0963,  0.1117,  0.1898,  ...,  0.1214,  0.1565, -0.0877],\n",
       "         ...,\n",
       "         [-0.0310,  0.1439, -0.0608,  ...,  0.0596,  0.0313, -0.0884],\n",
       "         [ 0.0678,  0.0133, -0.0158,  ..., -0.0106, -0.1032,  0.1046],\n",
       "         [ 0.0837, -0.1673,  0.1950,  ...,  0.1291,  0.0456, -0.0165]],\n",
       "        device='cuda:0', grad_fn=<MmBackward>),\n",
       " tensor([[-2.4464e-01, -4.2052e-02,  1.1102e-01,  ..., -1.0627e-01,\n",
       "           6.0265e-02, -3.7288e-02],\n",
       "         [-2.1609e-01,  9.6045e-02,  2.4408e-02,  ..., -5.7855e-02,\n",
       "          -1.6879e-01,  4.4607e-02],\n",
       "         [ 4.0250e-02,  7.0597e-02, -6.0260e-02,  ...,  1.4042e-02,\n",
       "           5.4368e-02, -9.7940e-02],\n",
       "         ...,\n",
       "         [ 1.1262e-01,  1.0114e-01,  2.6866e-02,  ...,  1.8169e-01,\n",
       "           9.5211e-02,  1.0834e-01],\n",
       "         [ 1.1141e-01,  1.2812e-02, -1.1415e-01,  ..., -7.5905e-02,\n",
       "          -1.3190e-02,  1.5316e-02],\n",
       "         [-6.4776e-05, -3.8403e-02,  7.4222e-02,  ..., -1.0041e-02,\n",
       "          -1.0706e-01, -1.1395e-01]], device='cuda:0', grad_fn=<MmBackward>),\n",
       " tensor([[ 0.0199,  0.0985, -0.0127,  ..., -0.0644, -0.0095,  0.0801],\n",
       "         [ 0.0235, -0.0442, -0.0290,  ...,  0.0267, -0.0211,  0.0437],\n",
       "         [ 0.0716,  0.0877,  0.1352,  ..., -0.0101,  0.0295, -0.0359],\n",
       "         ...,\n",
       "         [ 0.0176, -0.0591, -0.1298,  ...,  0.0406, -0.0115,  0.0287],\n",
       "         [-0.0972,  0.0595, -0.0222,  ...,  0.1098,  0.0101,  0.0489],\n",
       "         [-0.1462, -0.1171, -0.0124,  ..., -0.0424, -0.0352, -0.0463]],\n",
       "        device='cuda:0', grad_fn=<MmBackward>),\n",
       " tensor([[-1.3879e-01, -1.4478e-04, -3.0062e-02,  ...,  9.1806e-02,\n",
       "           4.0617e-02,  3.8519e-02],\n",
       "         [-4.1898e-02,  3.1792e-03,  2.8954e-03,  ...,  2.7927e-02,\n",
       "           7.4892e-02,  8.0067e-02],\n",
       "         [ 4.7534e-03, -1.9828e-01,  9.8176e-02,  ...,  8.8351e-03,\n",
       "          -4.3342e-02,  5.4405e-02],\n",
       "         ...,\n",
       "         [ 3.6030e-02, -3.1063e-02,  1.0442e-01,  ...,  2.0108e-02,\n",
       "          -1.6136e-02, -6.6370e-03],\n",
       "         [ 6.7435e-02, -1.9971e-02,  2.3672e-02,  ..., -8.2317e-02,\n",
       "           4.8032e-02, -1.0253e-01],\n",
       "         [ 9.7422e-03,  5.6546e-02, -9.1402e-02,  ..., -1.6511e-01,\n",
       "           7.6638e-02,  1.8514e-03]], device='cuda:0', grad_fn=<MmBackward>),\n",
       " tensor([[-0.0887, -0.1002, -0.0750,  ..., -0.1052,  0.0401, -0.1002],\n",
       "         [ 0.0654, -0.0590,  0.0799,  ...,  0.0323,  0.0051, -0.1555],\n",
       "         [ 0.0240, -0.0766, -0.0037,  ..., -0.0438, -0.0678, -0.0032],\n",
       "         ...,\n",
       "         [ 0.0871, -0.1279,  0.0676,  ..., -0.0667, -0.1442,  0.0012],\n",
       "         [ 0.0057, -0.0281,  0.1048,  ...,  0.0711, -0.0376,  0.0777],\n",
       "         [ 0.0867,  0.0150, -0.0841,  ...,  0.0185, -0.0513, -0.0537]],\n",
       "        device='cuda:0', grad_fn=<MmBackward>),\n",
       " tensor([[-0.0214,  0.0316,  0.0518,  ...,  0.0264,  0.0903,  0.1201],\n",
       "         [ 0.0182, -0.0012, -0.0013,  ...,  0.1120,  0.0294,  0.1232],\n",
       "         [-0.0875,  0.0010,  0.1441,  ..., -0.0142,  0.1230, -0.1249],\n",
       "         ...,\n",
       "         [ 0.0007,  0.0150, -0.0932,  ..., -0.0431, -0.0297, -0.0196],\n",
       "         [-0.0462,  0.0362, -0.0108,  ...,  0.0086, -0.0613,  0.0546],\n",
       "         [-0.0100, -0.1623, -0.0009,  ...,  0.0754,  0.0837, -0.0862]],\n",
       "        device='cuda:0', grad_fn=<MmBackward>),\n",
       " tensor([[ 0.0889, -0.0689, -0.0048,  ..., -0.0507, -0.0188,  0.0411],\n",
       "         [ 0.0427,  0.0154, -0.0775,  ...,  0.0559, -0.0054, -0.0315],\n",
       "         [-0.0815, -0.1122, -0.0824,  ..., -0.1868,  0.0554, -0.0685],\n",
       "         ...,\n",
       "         [ 0.0333,  0.0325, -0.0741,  ..., -0.0448,  0.0410,  0.0449],\n",
       "         [-0.0256, -0.0964,  0.0247,  ...,  0.1114,  0.0949,  0.0573],\n",
       "         [ 0.0468, -0.0192,  0.0503,  ...,  0.0390, -0.0981, -0.1163]],\n",
       "        device='cuda:0', grad_fn=<MmBackward>),\n",
       " tensor([[-0.0890, -0.1326, -0.2010,  ..., -0.0402, -0.0214,  0.0453],\n",
       "         [-0.0564, -0.0258, -0.0870,  ..., -0.0193, -0.1184,  0.0259],\n",
       "         [-0.0955, -0.0960,  0.0009,  ...,  0.0475,  0.0588, -0.0904],\n",
       "         ...,\n",
       "         [-0.0831,  0.0060, -0.0321,  ...,  0.0242, -0.1502,  0.0411],\n",
       "         [ 0.0460,  0.0330,  0.1945,  ..., -0.0663, -0.0857, -0.0495],\n",
       "         [ 0.0041,  0.0960, -0.0617,  ...,  0.0593, -0.0238, -0.0388]],\n",
       "        device='cuda:0', grad_fn=<MmBackward>),\n",
       " tensor([[ 1.1401e-01,  6.4933e-02,  1.3931e-02,  ...,  9.2412e-02,\n",
       "          -1.6699e-03, -3.1016e-02],\n",
       "         [-1.8042e-02,  4.1912e-02,  8.5409e-02,  ..., -6.0812e-02,\n",
       "           1.1631e-01,  2.3809e-02],\n",
       "         [-3.0631e-02, -1.2881e-01,  1.3236e-01,  ..., -9.2223e-02,\n",
       "           4.0152e-05,  4.1416e-02],\n",
       "         ...,\n",
       "         [-8.1097e-02,  5.2627e-02,  5.6495e-02,  ..., -5.8812e-02,\n",
       "           1.7643e-02,  6.8870e-02],\n",
       "         [ 4.4323e-02,  6.8474e-02,  2.9268e-02,  ...,  6.7800e-02,\n",
       "           4.0867e-02,  4.2137e-02],\n",
       "         [ 3.0558e-02,  6.8434e-02, -5.6423e-02,  ...,  9.0329e-06,\n",
       "          -6.4178e-02, -8.9817e-02]], device='cuda:0', grad_fn=<MmBackward>)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_reduce(w, c = 10, r = 10, t_max = 100, m_min = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = {1: (2, 1), 3: (4, 0), 4: (3, 1), 2: (1, 5), 0: (0, 6)}\n",
    "sorted_by_value = sorted(x.items(), key=lambda kv: kv[1])\n",
    "sorted_by_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [1, 2, 3, 4, 5, 6]\n",
    "A[0:2-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[[1, 2],[3, 4]],[[5, 6],[7, 8]],[[9, 0],[11,12]]])\n",
    "A_tensor = torch.from_numpy(A)\n",
    "A_tensor"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "dl_paper.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
